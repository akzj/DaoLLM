# 训练监控指南

## GPU利用率为0%的原因

### 正常情况

训练刚开始时，GPU利用率0%是**正常的**，原因如下：

1. **数据加载阶段**（当前阶段）
   - 从磁盘加载数据集文件（.arrow格式）
   - 数据集可能很大，需要时间加载
   - CPU密集型操作，GPU不参与

2. **数据预处理阶段**
   - Tokenization（分词）
   - 数据整理和批处理
   - 这些操作主要在CPU上进行

3. **模型初始化阶段**
   - 虽然模型已加载到GPU（显存已占用）
   - 但还没有开始前向/反向传播
   - GPU处于等待状态

### 训练流程时间线

```
1. 加载模型到GPU          [显存占用↑, GPU利用率0%] ✅ 已完成
2. 加载数据集              [CPU忙碌, GPU利用率0%]   ⏳ 当前阶段
3. 数据预处理              [CPU忙碌, GPU利用率0%]   ⏳ 即将进行
4. 训练循环开始            [GPU利用率↑↑↑]          ⏳ 等待中
```

## 如何判断训练是否正常

### ✅ 正常指标

- ✅ 进程正在运行（CPU使用率高）
- ✅ GPU显存已占用（12GB+）
- ✅ 进程正在读取数据集文件
- ✅ 日志文件存在

### ⚠️ 需要关注的情况

如果以下情况持续**超过10分钟**，可能需要检查：

- GPU利用率一直为0%
- CPU使用率突然降到很低
- 进程没有响应

## 监控命令

### 实时监控GPU
```bash
watch -n 1 nvidia-smi
```

### 检查训练进度
```bash
cd fine-tune
python check_training_progress.py
```

### 查看进程状态
```bash
ps aux | grep train_lora
```

### 查看最新日志
```bash
cd fine-tune/output/logs
tensorboard --logdir=. --port=6006
# 然后在浏览器打开 http://localhost:6006
```

## 预期时间

根据你的配置：
- **数据集大小**: 14个文件（data-00000到data-00013）
- **每个文件**: ~491MB
- **总数据量**: ~6.8GB

预计时间：
- 数据加载: 1-3分钟
- 数据预处理: 2-5分钟
- 训练开始后GPU利用率会立即上升

## 训练开始后的预期GPU利用率

训练循环开始后，你应该看到：
- GPU利用率: 80-100%
- GPU温度: 上升
- 显存使用: 稳定在12-14GB
- 训练日志: 开始输出loss值

## 如果长时间没有进展

如果超过10分钟GPU利用率仍为0%：

1. 检查进程是否还在运行
2. 查看是否有错误信息
3. 检查数据集是否损坏
4. 考虑减少数据集大小进行测试

